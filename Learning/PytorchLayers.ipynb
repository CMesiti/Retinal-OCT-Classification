{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AT-LGbete007"
   },
   "source": [
    "# Pytorch Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 5737,
     "status": "ok",
     "timestamp": 1732289738207,
     "user": {
      "displayName": "caleb mesiti",
      "userId": "01637469003266537747"
     },
     "user_tz": 300
    },
    "id": "oxYCm1Iufvj8"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fwe\n",
    "import torch.optim as optim\n",
    "import cv2 as cv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5WdFjiPfu_g"
   },
   "source": [
    "> Defining a neural network in pytorch, we define layers that will take data and perform a series of computations. Each layer is\n",
    "interconnected with a number of input nodes and output nodes.\n",
    "\n",
    "When defining a neural net in pytorch we must have a __init__ function, that references nn.module __init__.\n",
    "The class that inherits from nn.module will be where you put your fully connected layers.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZA1pwfMgACn"
   },
   "source": [
    "- Convolution layers are useful for extracting features from the images, by adding each element of the image to its neighbors weighted by a Kernel\n",
    "- The forward function will pass the data to our computation graph (nueral network)\n",
    "\n",
    "- __init__ function holds fully connected layers, forward function holds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 269,
     "status": "ok",
     "timestamp": 1732304909807,
     "user": {
      "displayName": "caleb mesiti",
      "userId": "01637469003266537747"
     },
     "user_tz": 300
    },
    "id": "-wZ6WJ7Frc00",
    "outputId": "9264fe72-3625-49e4-b11e-97a58debadf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (convolution1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (convolution2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout1): Dropout2d(p=0.25, inplace=False)\n",
      "  (dropout2): Dropout2d(p=0.5, inplace=False)\n",
      "  (fullyconnected): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (fullyconnected2): Linear(in_features=128, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Simple CNN Structure\n",
    "\n",
    "\n",
    "class  SimpleCNN(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleCNN, self). __init__()\n",
    "\n",
    "    #fully connected layers, The convolutional layer takes 1 input channel which will be an image\n",
    "    #the output will be a 32 covolutional features, with a square kernel size of 3.\n",
    "    self.convolution1 = nn.Conv2d(in_channels=1, out_channels = 32, kernel_size=3, stride=1)\n",
    "\n",
    "    # Second convolutional layer taking the 32 outputs from the previous\n",
    "    # outputting 64 convolutional features with a square kernel size of 3.\n",
    "    self.convolution2 = nn.Conv2d(in_channels= 32,out_channels=64, kernel_size=3, stride=1)\n",
    "\n",
    "\n",
    "    # these layers ensure adjacent pixels are 0s or all active.\n",
    "    self.dropout1 = nn.Dropout2d(0.25)\n",
    "    self.dropout2 = nn.Dropout2d(0.5)\n",
    "\n",
    "    self.fullyconnected  = nn.Linear(in_features=9216, out_features=128)\n",
    "    #this second fully connected layer then outputs are 3 labels\n",
    "    self.fullyconnected2 = nn.Linear(in_features=128, out_features=3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "my_simpleCNN = SimpleCNN()\n",
    "print(my_simpleCNN)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BILnAuca0OH2"
   },
   "source": [
    "### Using State Dict to save & Load models.\n",
    "- how does our AI project work? RAG, embedding,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m6nuxcie0N17"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZ9rt1jzrky9"
   },
   "source": [
    "## Backbones for a Model\n",
    "\n",
    "\n",
    "\n",
    "*   List item\n",
    "*   List item\n",
    "\n",
    "\n",
    "\n",
    "*   List item\n",
    "*   List item\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPJV1nNwGVbYIwXjA5uEaJi",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
